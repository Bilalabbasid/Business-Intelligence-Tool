# GitHub Actions workflow for BI Tool CI/CD
name: BI Tool CI/CD

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

env:
  PYTHON_VERSION: '3.9'
  NODE_VERSION: '18'

jobs:
  # Backend testing and quality checks
  backend-tests:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: bi_tool_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      mongodb:
        image: mongo:5.0
        ports:
          - 27017:27017
      
      redis:
        image: redis:6
        ports:
          - 6379:6379
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y postgresql-client
    
    - name: Install Python dependencies
      run: |
        cd bi_tool
        pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-django pytest-cov pytest-mock coverage
    
    - name: Set up environment variables
      run: |
        echo "DATABASE_URL=postgresql://postgres:postgres@localhost:5432/bi_tool_test" >> $GITHUB_ENV
        echo "MONGO_URL=mongodb://localhost:27017/bi_tool_test" >> $GITHUB_ENV
        echo "REDIS_URL=redis://localhost:6379/1" >> $GITHUB_ENV
        echo "DJANGO_SETTINGS_MODULE=bi_tool.settings" >> $GITHUB_ENV
        echo "SECRET_KEY=test-secret-key-for-ci" >> $GITHUB_ENV
    
    - name: Run database migrations
      run: |
        cd bi_tool
        python manage.py migrate
    
    - name: Run Django system checks
      run: |
        cd bi_tool
        python manage.py check --deploy
    
    - name: Run unit tests with coverage
      run: |
        cd bi_tool
        pytest dq/tests/ -v --cov=dq --cov-report=xml --cov-report=html --cov-fail-under=80
    
    - name: Run DQ system integration tests
      run: |
        cd bi_tool
        pytest dq/tests/test_dq_system.py::DQIntegrationTestCase -v
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: bi_tool/coverage.xml
        fail_ci_if_error: true
    
    - name: Run security checks
      run: |
        cd bi_tool
        pip install bandit safety
        bandit -r . -f json -o bandit-report.json || true
        safety check --json > safety-report.json || true
    
    - name: Upload test artifacts
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: test-reports
        path: |
          bi_tool/htmlcov/
          bi_tool/coverage.xml
          bi_tool/bandit-report.json
          bi_tool/safety-report.json

  # Frontend testing
  frontend-tests:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: bi-frontend/package-lock.json
    
    - name: Install dependencies
      run: |
        cd bi-frontend
        npm ci
    
    - name: Run linting
      run: |
        cd bi-frontend
        npm run lint
    
    - name: Run unit tests
      run: |
        cd bi-frontend
        npm run test -- --coverage --watchAll=false
    
    - name: Build frontend
      run: |
        cd bi-frontend
        npm run build
    
    - name: Upload frontend artifacts
      uses: actions/upload-artifact@v3
      with:
        name: frontend-build
        path: bi-frontend/dist/

  # Performance and load tests
  performance-tests:
    runs-on: ubuntu-latest
    needs: [backend-tests]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: bi_tool_perf
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        cd bi_tool
        pip install -r requirements.txt
        pip install pytest pytest-django pytest-benchmark psutil
    
    - name: Run performance tests
      run: |
        cd bi_tool
        pytest dq/tests/test_performance.py -v -m slow --benchmark-json=benchmark.json
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/bi_tool_perf
    
    - name: Upload performance results
      uses: actions/upload-artifact@v3
      with:
        name: performance-results
        path: bi_tool/benchmark.json

  # Code quality and security
  code-quality:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
      with:
        fetch-depth: 0  # Needed for SonarCloud
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install quality tools
      run: |
        pip install flake8 black isort mypy pylint
    
    - name: Run code formatting check
      run: |
        cd bi_tool
        black --check .
        isort --check-only .
    
    - name: Run linting
      run: |
        cd bi_tool
        flake8 . --max-line-length=88 --extend-ignore=E203,W503
    
    - name: Run type checking
      run: |
        cd bi_tool
        mypy dq/ --ignore-missing-imports
    
    - name: Run pylint
      run: |
        cd bi_tool
        pylint dq/ --disable=C0114,C0115,C0116 --load-plugins=pylint_django
      continue-on-error: true
    
    - name: SonarCloud Scan
      uses: SonarSource/sonarcloud-github-action@master
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

  # Docker build and push
  docker-build:
    runs-on: ubuntu-latest
    needs: [backend-tests, frontend-tests]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v2
    
    - name: Log in to Docker Hub
      uses: docker/login-action@v2
      with:
        username: ${{ secrets.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_PASSWORD }}
    
    - name: Build and push backend image
      uses: docker/build-push-action@v4
      with:
        context: ./bi_tool
        push: true
        tags: |
          ${{ secrets.DOCKER_USERNAME }}/bi-tool-backend:latest
          ${{ secrets.DOCKER_USERNAME }}/bi-tool-backend:${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max
    
    - name: Build and push frontend image
      uses: docker/build-push-action@v4
      with:
        context: ./bi-frontend
        push: true
        tags: |
          ${{ secrets.DOCKER_USERNAME }}/bi-tool-frontend:latest
          ${{ secrets.DOCKER_USERNAME }}/bi-tool-frontend:${{ github.sha }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  # Deployment (staging)
  deploy-staging:
    runs-on: ubuntu-latest
    needs: [docker-build]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    environment: staging
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Deploy to staging
      run: |
        # Add your deployment commands here
        # For example, using kubectl or docker-compose
        echo "Deploying to staging environment..."
        # kubectl apply -f k8s/staging/
        # or
        # docker-compose -f docker-compose.staging.yml up -d
    
    - name: Run smoke tests
      run: |
        # Add smoke tests to verify deployment
        echo "Running smoke tests..."
        # curl -f http://staging.bi-tool.com/health/ || exit 1
    
    - name: Notify deployment
      uses: 8398a7/action-slack@v3
      if: always()
      with:
        status: ${{ job.status }}
        channel: '#deployments'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        text: |
          Staging deployment ${{ job.status }}
          Commit: ${{ github.sha }}
          Author: ${{ github.actor }}

  # Production deployment (manual approval required)
  deploy-production:
    runs-on: ubuntu-latest
    needs: [deploy-staging]
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    environment: production
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Deploy to production
      run: |
        echo "Deploying to production environment..."
        # Add production deployment commands
    
    - name: Run production smoke tests
      run: |
        echo "Running production smoke tests..."
        # Add production-specific smoke tests
    
    - name: Notify production deployment
      uses: 8398a7/action-slack@v3
      if: always()
      with:
        status: ${{ job.status }}
        channel: '#production'
        webhook_url: ${{ secrets.SLACK_WEBHOOK }}
        text: |
          ðŸš€ Production deployment ${{ job.status }}
          Commit: ${{ github.sha }}
          Author: ${{ github.actor }}

  # Scheduled data quality checks
  scheduled-dq-checks:
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule'
    
    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: bi_tool_prod
        ports:
          - 5432:5432
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install dependencies
      run: |
        cd bi_tool
        pip install -r requirements.txt
    
    - name: Run DQ checks
      run: |
        cd bi_tool
        python manage.py run_dq_checks --sync
      env:
        DATABASE_URL: ${{ secrets.PROD_DATABASE_URL }}
    
    - name: Generate DQ report
      run: |
        cd bi_tool
        python manage.py export_dq_data --format html --output dq_report.html
    
    - name: Upload DQ report
      uses: actions/upload-artifact@v3
      with:
        name: dq-report-${{ github.run_number }}
        path: bi_tool/dq_report.html

# Schedule for running DQ checks
# Uncomment and modify as needed:
# on:
#   schedule:
#     - cron: '0 */6 * * *'  # Every 6 hours